{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maharshi112/looking-forward/blob/master/Day_4_Numpy_4_Class_Prcatice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d54f6eac",
      "metadata": {
        "id": "d54f6eac"
      },
      "source": [
        "## <code style=\"background:yellow;color:black\">Copies of Data</code>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ccb080",
      "metadata": {
        "id": "73ccb080"
      },
      "source": [
        "**As a data scientist, you will be working with millions of rows of data. So, numpy on top of being very fast, also has to be memory efficient, because if its not memory efficient your computer or system might run out of memory, and you wont be able to work with that dataset.**\n",
        "\n",
        "So ultimately, storage space is a baseline requirement for numpy to be able to work with data because memory is continuosly either occupied or freed with each line of the program or with execution every of task. **Therefore, numpy internally has done a lot of optimizations so that it can optimize on storage / memory space.**\n",
        "\n",
        "Lets suppose there is a bunch of data in excel. This data is for multiple cars. The cars data has 3 columns called Car model, Manufacturer and Date of launch. There are some entries i.e. rows in the data. <mark>REFER NOTES TO SEE DATA.</mark>\n",
        "\n",
        "Lets suppose you only have to show data for tata, what would you do? Will you copy all the tata entries to another excel sheet or simply apply a filter to filter out tata entries? Obviously you will apply the filter on the manufacturer, which means that filter will show you the tata data, but the rest of the data will still be there.\n",
        "\n",
        "**It means internally all the data is present but only filtered data is visible to you as the user. <mark>OR WE CAN ALSO SAY THAT BOTH THE DATAFRAMES OR BOTH THESE SOURCES OF DATA IS THE SAME, WE ARE JUST LOOKING AT DIFFERENT VIEWS OF THE DATA.</mark>**\n",
        "\n",
        "Internally there is one single dataset, but we are just looking at different views of that same data. In one view, we are looking at all the manufacturers and in another view we are only looking at tata data.\n",
        "\n",
        "Now, when it comes to numpy, we are doing as lot of operations on data. Some of those operations are permananet and some of those opearations are operations which can be either reversible or changed or are only done to present the data in a different format. These opearations do not change the structure or the value of the data but they just present the data differently.\n",
        "\n",
        "**So NUMPY AUTOMATICALLY HAS DIVIDED ALL ITS OPERATIONS INTO THESE TWO CATEGORIES.**\n",
        "\n",
        "**<mark>Category 1</mark>** are those opeartions which are permanent or important operations on data.\n",
        "\n",
        "**<mark>Category 2</mark>** are operations which are just on the look of data or view of the data.\n",
        "\n",
        "**AND IN BOTH THESE CASES NUMPY HANDLES MEMORY DIFFERENTLY. We will see this in action.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6932e7",
      "metadata": {
        "id": "1b6932e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87102d44",
      "metadata": {
        "id": "87102d44"
      },
      "outputs": [],
      "source": [
        "a = np.arange(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d25634a",
      "metadata": {
        "id": "0d25634a",
        "outputId": "934896aa-e923-4e23-c05e-9b36474f986a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3232e12f",
      "metadata": {
        "id": "3232e12f"
      },
      "outputs": [],
      "source": [
        "b = a.reshape(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6c6acb0",
      "metadata": {
        "id": "a6c6acb0",
        "outputId": "add3221c-6329-45c0-a33b-90943b47cb82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [2, 3]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3fefc23",
      "metadata": {
        "id": "b3fefc23"
      },
      "source": [
        "If we look at a and b, both a and b are similar in data but different in the view of that data, which means they look and feel different and are presented differently but the data within them is the same.\n",
        "\n",
        "**So in some such cases, what numpy does is it creates a <code style=\"background:yellow;color:black\">SHALLOW COPY of data</code>.**\n",
        "\n",
        "* **A shallow copy of an array means a new array that is a copy of the original array's data and shape but shares the same memory addresses as the original array. In other words, both of these arrays are sharing the same memory addresses.**\n",
        "* **Changes made to the data within a shallow copy will also affect the original array, and vice versa.**\n",
        "* To prove it, below we are changing a[0] to 100, obviously \"a\" gets modified and now has 100 as its 1st element, BUT B ALSO HAS THE SAME 100. IT ALSO CHANGED ITS 1ST ELEMENT.**  \n",
        "\n",
        "**<mark>Numpy creates a shallow copy WHEN RESHAPING.</mark>**\n",
        "\n",
        "**There is also a <code style=\"background:yellow;color:black\">DEEP COPY.</code>**\n",
        "\n",
        "* **A deep copy of an array is a completely independent copy of the original array, which means it has its own memory address. In other words, both of these arrays have different same memory addresses and are not sharing them.**\n",
        "* **Changes made to a deep copy do not affect the original array, and vice versa.**\n",
        "\n",
        "** We will learn a sure shot way to understand where will numpy create a shallow copy and where will it create a deep copy. **\n",
        "\n",
        "So, what numpy has done internally, is that all the elements are shared between both the array a and b, so that when we modify one of the elements for one of the arrays, since the memory address was common and since the elements were shared between the two arrays, the b array also got affected. Here, numpy did not duplicate the data two times, what it did is actually created two pointers or references to that data, one reference was \"a\" and one reference was \"b\"; b and a were both looking at the data in different ways, but ultimately the data was exactly the same.\n",
        "\n",
        "**To prove this or show this, numpy has a unique function called <mark>shares_memory()</mark>.**\n",
        "\n",
        "* This is used to determine whether two arrays share the same memory block or addresses. This function returns a boolean value, indicating whether the two arrays share memory or not.\n",
        "* The np.shares_memory() function takes two NumPy arrays as arguments and checks if they have overlapping memory or if they are views of the same data. If they share memory, the function returns True; otherwise, it returns False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed5bf4ea",
      "metadata": {
        "id": "ed5bf4ea"
      },
      "outputs": [],
      "source": [
        "a[0] = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "803f37a8",
      "metadata": {
        "id": "803f37a8",
        "outputId": "cf7d521a-db16-4f20-c515-fcecf3a4887a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([100,   1,   2,   3])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a523379",
      "metadata": {
        "id": "5a523379",
        "outputId": "e9cb5473-1359-4fbc-9f9b-c3b1619cdd7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[100,   1],\n",
              "       [  2,   3]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0b158e5",
      "metadata": {
        "id": "a0b158e5"
      },
      "source": [
        "** This means that either \"b\" is a shallow copy of \"a\" or \"a\" is a shallow copy of \"b\" **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eed33c2",
      "metadata": {
        "id": "8eed33c2",
        "outputId": "259e4ca8-7bae-45dd-e69c-4d283ffadb37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c7670b",
      "metadata": {
        "id": "90c7670b"
      },
      "source": [
        "<mark>Now, when is numpy creating deep copy or how it works?</mark>\n",
        "\n",
        "* Below we created a 1D np array \"a\".\n",
        "* We also created another array \"c\" and make it a + 2.\n",
        "* **Numpy considers addition, subtraction, multiplication these kind of operations to be more permanent in nature, because all the individual elements are updated or changed i.e. data is changed.**\n",
        "* So if we create c from a, c has different data than a.\n",
        "* Now if we check by \"shares_memory()\", we will see that a and c do not share memory.\n",
        "* We can further prove this by changing first element of c to 100, and c array gets updated as we can see below. <mark>BUT ARRAY A IS NOT CHANGED AT ALL, ITS FIRST ELEMENT IS AS IT IS, IT HASNT CHANGED.</mark> Why because c was stored in an entirely memory location and a has been stored in an entirely different location and they do not share their memory addresses, and python can clear identify where a and c are located in memory locations.\n",
        "\n",
        "**\"C\" IS A DEEP COPY OF \"A\". Why do we say that c is a copy of a although c is altogether a different array in terms of data? - BECAUSE C COPIED THE DATA FROM A AND THEN MODIFIED THE DATA BY ADDING 2 TO IT. IN OTHER WORDS, C TOOK A DEEP COPY OF A AND THEN ADDED 2 TO IT.**\n",
        "\n",
        "**Numpy does all this decisions on whether to share memory or not internally on its own, but numpy has given us <mark>shares_memory()</mark> function to check the memory sharing between two np arrays.**\n",
        "\n",
        "** Actually there are so many cases that in some memory is shared and in some memory isnt shared, and so remembering all those cases becomes difficult, so we have this function to check the same. **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4988e1a9",
      "metadata": {
        "id": "4988e1a9"
      },
      "outputs": [],
      "source": [
        "a = np.arange(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc0de62",
      "metadata": {
        "id": "1fc0de62"
      },
      "outputs": [],
      "source": [
        "c = a + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fc9f9ce",
      "metadata": {
        "id": "1fc9f9ce",
        "outputId": "9b78587a-ba29-4706-ecdf-3e282e61a6b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "812832a0",
      "metadata": {
        "id": "812832a0",
        "outputId": "ce9636db-150a-43fe-8f72-fd0690b9e62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 3, 4, 5])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdb0d59e",
      "metadata": {
        "id": "cdb0d59e",
        "outputId": "dfb39b24-dcfd-4de7-bbb0-101e419212be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55eda195",
      "metadata": {
        "id": "55eda195"
      },
      "outputs": [],
      "source": [
        "c[0] = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedbeef7",
      "metadata": {
        "id": "bedbeef7",
        "outputId": "91bf88b5-46c5-42de-9bd7-cdbf84ef96a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([100,   3,   4,   5])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c975789",
      "metadata": {
        "id": "8c975789",
        "outputId": "bfd0cf87-d4c7-48c9-fe78-e40e3d2e8b7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b05f929",
      "metadata": {
        "id": "4b05f929"
      },
      "source": [
        "** Now here in this case below, even though \"a\" and \"b\" both hold the same value or data, numpy doesvnot share memory addresses of these arrays, and it created a deep copy because it figured that a multiplication operation requires a deep copy. **  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2603427",
      "metadata": {
        "id": "a2603427"
      },
      "outputs": [],
      "source": [
        "a = np.array([0,0,0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d3bcf0",
      "metadata": {
        "id": "b7d3bcf0",
        "outputId": "9a72f62b-7f5d-46ef-a92f-db040b2dd17f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d5d4162",
      "metadata": {
        "id": "0d5d4162"
      },
      "outputs": [],
      "source": [
        "b = a * 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a2c41e1",
      "metadata": {
        "id": "4a2c41e1",
        "outputId": "d8f18ea4-212f-4aad-949f-b44c9243abcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 0]), array([0, 0, 0, 0]))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ca0413",
      "metadata": {
        "id": "72ca0413",
        "outputId": "6c5547a7-01c8-4587-e9d5-ddc5452fa0f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc337ce8",
      "metadata": {
        "id": "dc337ce8"
      },
      "source": [
        "* Here, in this case below, \"a\" and \"b\" have different data, they are not the same exact lists.\n",
        "* But in this case, numpy allows sharing memory addresses of these two arrays.\n",
        "* Lets look at it like the excel example previously.\n",
        "* We can see \"b\" as a filter that has been applied on \"a\" or that \"b\" is a subset of \"a\".\n",
        "* So all the data in \"b\" is still present inside of \"a\", which means if we modify the data in \"a\", data in \"b\" will be modified too because \"b\" is a subset of \"a\".\n",
        "* We change the 1st element in \"b\" to 1000 and we check \"a\" is also updated.\n",
        "* <mark>REFER NOTES VERY WELL EXPLAINED WITH VISUALIZATION.</mark>\n",
        "* So, here we see that 2 different np arrays dont necessarily share data but they can share memory addresses because one can be a subset of the other.\n",
        "\n",
        "Deep copy of one array wrt another array means both the arrays are stored at different memory locations in memory.\n",
        "\n",
        "<mark>So, the cases are very varied apart. There can be cases where the data or values is different but a shallow copy is created and conversely there can be cases where the values can be same but the copy created is a deep copy.</mark>\n",
        "\n",
        "**NUMPY DECIDES INTERNALLY AUTOMATICALLY WHICH COPY TO CREATE OR WHICH FORMAT OR RULE TO FOLLOW, which is the reason numpy has given us this shares_memory() function.**\n",
        "\n",
        "** You can try or explore further and see whichc cases create a deep copy and which creates a shallow one. See what copies different kind of operations like arithmetic, logical, masking, indexing, slicing etc create. **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e955c430",
      "metadata": {
        "id": "e955c430"
      },
      "outputs": [],
      "source": [
        "a = np.arange(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d4284b",
      "metadata": {
        "id": "b2d4284b",
        "outputId": "d417c74e-b0c7-49e5-c788-d4c5d4e14cb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4a29db",
      "metadata": {
        "id": "bb4a29db"
      },
      "outputs": [],
      "source": [
        "b = a[::2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c67b0c6",
      "metadata": {
        "id": "7c67b0c6",
        "outputId": "3f88f30d-9855-4126-d7e4-925c473219bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223353bc",
      "metadata": {
        "id": "223353bc",
        "outputId": "1e158978-da0d-4dac-e166-e4d3945c6123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 2, 4, 6, 8])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "810ae9c6",
      "metadata": {
        "id": "810ae9c6",
        "outputId": "bf98a29c-9990-4e4c-8228-5b88d76ebfcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b298fc",
      "metadata": {
        "id": "36b298fc"
      },
      "outputs": [],
      "source": [
        "b[0] = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e617ce00",
      "metadata": {
        "id": "e617ce00",
        "outputId": "3c24f5be-5c45-4d5d-8910-e6e1adc3eb9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1000,    1,    2,    3,    4,    5,    6,    7,    8,    9])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "535f9d7d",
      "metadata": {
        "id": "535f9d7d",
        "outputId": "f6fab8c2-549f-445c-fc42-8e2f0e5e54ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 % 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64f34571",
      "metadata": {
        "id": "64f34571"
      },
      "source": [
        "** This is another example to see if a shallow or deep copy is created, and we see a deep copy is created. **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe037f40",
      "metadata": {
        "id": "fe037f40"
      },
      "outputs": [],
      "source": [
        "a = np.arange(6)\n",
        "\n",
        "b = a[a % 1 == 0]\n",
        "\n",
        "b[0] = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3757e5a1",
      "metadata": {
        "id": "3757e5a1",
        "outputId": "f9e39788-4f33-4fc8-a309-3c412513d3dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a972ab53",
      "metadata": {
        "id": "a972ab53",
        "outputId": "c6dda1a1-7374-48b1-b00c-e1f03afa445a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10,  1,  2,  3,  4,  5])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfa75e03",
      "metadata": {
        "id": "cfa75e03",
        "outputId": "22186aaa-59f9-4629-930a-40ea2846b5fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831e1f27",
      "metadata": {
        "id": "831e1f27"
      },
      "source": [
        "So, up and untill this point of time in disussion, we can to understand the following:\n",
        "\n",
        "* **<mark>Shallow Copy is created in these cases - Reshaping, Slicing....(and the list goes on which you can explore)</mark>**\n",
        "* **<mark>Deep Copy is created in these cases - Arithmetic Operations, Masking....(and the list goes on which you can explore)</mark>**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26dba14b",
      "metadata": {
        "id": "26dba14b"
      },
      "source": [
        "* Now, we know numpy creates shallow and deep copies of arrays and it handles memory management on its own.\n",
        "* BUT WHAT IF WE WANT A SHALLOW OR DEEP COPY EXPLICITLY WITHOUT DOING ANY OPERATION ON THAT ARRAY, WITHOUT NUMPY DOING EVERYTHING ON ITS OWN, MEANS NUMPY DECIDING WHETHER IT WILL BE SHALLOW OR DEEP ON ITS OWN?\n",
        "\n",
        "**<mark>There are 2 functions for this -- <code style=\"background:yellow;color:black\">view()</code> creates shallow copy of array and <code style=\"background:yellow;color:black\">copy()</code> creates deep copy of array.</mark>**\n",
        "\n",
        "In the following examples we can see that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fef2658",
      "metadata": {
        "id": "0fef2658"
      },
      "outputs": [],
      "source": [
        "a = np.arange(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cefa530",
      "metadata": {
        "id": "2cefa530"
      },
      "source": [
        "** Creates a shallow copy of \"a\". **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74ac778",
      "metadata": {
        "id": "d74ac778"
      },
      "outputs": [],
      "source": [
        "a_shallow_copy = a.view()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4a5899",
      "metadata": {
        "id": "cd4a5899",
        "outputId": "ab6b5a2e-6ea3-43bc-f8d8-9ebb2798abbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a, a_shallow_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a4bef98",
      "metadata": {
        "id": "3a4bef98",
        "outputId": "ccc939f8-59ca-4b7f-c000-e1f6fb25be48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddf2d6eb",
      "metadata": {
        "id": "ddf2d6eb",
        "outputId": "39d1fa5f-af8a-43ca-d9be-0a970e248e62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_shallow_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b9d480",
      "metadata": {
        "id": "79b9d480"
      },
      "outputs": [],
      "source": [
        "a_shallow_copy[0] = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9fb3f00",
      "metadata": {
        "id": "c9fb3f00",
        "outputId": "7e0505d8-185c-4402-f536-e287e11e358c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([100,   1,   2,   3,   4,   5,   6,   7,   8,   9])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b219e7e8",
      "metadata": {
        "id": "b219e7e8"
      },
      "outputs": [],
      "source": [
        "a = np.arange(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a843a2",
      "metadata": {
        "id": "d9a843a2"
      },
      "source": [
        "** Creates a deep copy of \"a\". **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7436aa08",
      "metadata": {
        "id": "7436aa08"
      },
      "outputs": [],
      "source": [
        "a_deep_copy = a.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b5517d6",
      "metadata": {
        "id": "1b5517d6",
        "outputId": "bd866420-6a1c-41a6-f03f-5f385972e0f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.shares_memory(a, a_deep_copy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "508f28a2",
      "metadata": {
        "id": "508f28a2"
      },
      "source": [
        "**<mark>Why we are learning this shallow and deep copies or memeory management of numpy at a very higher level?</mark>**\n",
        "\n",
        "* We should be aware of it because numpy functions that way or uses it for memeory optimization.\n",
        "* If we are not aware of this, then we might feel that our data is misbehaving.\n",
        "* We might not know why something else is changing while we are expecting something else.\n",
        "* So, its very important to know how numpy is handling the memory side of things.\n",
        "\n",
        "**We wont be using this concepts directly for data science, but this is sort of going to get applied unintentionally and we dont have control over it, which is why we should have a great understanding of it.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57dfbb5f",
      "metadata": {
        "id": "57dfbb5f"
      },
      "source": [
        "We can dive deep between shallow nad deep copies, you can refer to these official documetations of numpy:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d737caff",
      "metadata": {
        "id": "d737caff"
      },
      "source": [
        "#### `.copy()` -- Returns copy of the array.\n",
        "\n",
        "Documentation (`.copy()`): https://numpy.org/doc/stable/reference/generated/numpy.ndarray.copy.html#numpy.ndarray.copy\n",
        "\n",
        "Documentation: (`np.copy()`): https://numpy.org/doc/stable/reference/generated/numpy.copy.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e16c48",
      "metadata": {
        "id": "49e16c48"
      },
      "source": [
        "* When we are doing any operations on arrays, then numpy will decide automatically.\n",
        "* But when we want ourself to create a copy of array, then control is with us, we can decide whether we want a shallow copy or deep copy using **.copy() or .view()**, otherwise during opeartions as mentioned earlier numpy automatically decides because numpy handles memory allocations automatically.\n",
        "* Lets suppose we got a list that we need to sort.\n",
        "* But in our use case, we need to maintain or dont want to destroy the original list, so we will create a copy of it in another list and then sort that copied list.\n",
        "* Because lets suppose we need to present the original array and the sorted array both, so if we do an in-place sort on the original list, our unsorted original list is gone which we need to present somewhere.\n",
        "* One way of doing this is like the code below -- np.sort(a) doesnt sort the original \"a\" but creates a copy of \"a\" in a_sorted list and then sorts it.\n",
        "* Another way of doing it is to create a deep copy of \"a\" i.e. array \"b\".\n",
        "* We cant do a shallow copy of \"a\" because then if we would sort \"a\" then \"b\" would also change. So we can see in code below that \"b\" is sorted but \"a\" is not sorted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd752890",
      "metadata": {
        "id": "fd752890"
      },
      "outputs": [],
      "source": [
        "a = np.array([10,15,25,5,20,0,30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b45a206d",
      "metadata": {
        "id": "b45a206d"
      },
      "outputs": [],
      "source": [
        "a_sorted = np.sort(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bed17650",
      "metadata": {
        "id": "bed17650",
        "outputId": "ba54e40f-eae1-4a96-8fb2-51120566160f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10, 15, 25,  5, 20,  0, 30])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c1777dd",
      "metadata": {
        "id": "1c1777dd",
        "outputId": "c4d1fb4f-1531-4192-b7b8-54e36d1f7562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  5, 10, 15, 20, 25, 30])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b188034b",
      "metadata": {
        "id": "b188034b"
      },
      "outputs": [],
      "source": [
        "b = a.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce76cc9c",
      "metadata": {
        "id": "ce76cc9c"
      },
      "outputs": [],
      "source": [
        "b.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272e9ee2",
      "metadata": {
        "id": "272e9ee2",
        "outputId": "ceaaaaed-2da3-4f89-af4e-f19a65417d75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  5, 10, 15, 20, 25, 30])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa53682b",
      "metadata": {
        "id": "aa53682b",
        "outputId": "31fd64aa-7740-42d5-d0b5-e0a3e2accd58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10, 15, 25,  5, 20,  0, 30])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14978539",
      "metadata": {
        "id": "14978539"
      },
      "source": [
        "**So, in any case where we have to maintain original data, where we cant loose the structure, order, authenticity of the original data but still we have to do multiple operations -- THERE WE WILL BE CREATING DEEP COPIES, i.e. copies of data which do not modify the original data.**\n",
        "\n",
        "* We might do this frequently in data science.\n",
        "* When we will be exploring data, we will have to do a lot of operations on data and some of these operations will not be successful.\n",
        "* Whenever we will have unsuccessful operations, we will have to go back to the original data, but if we loose the original data, how will you do that?\n",
        "* **So if we do not create a deep copy of the original data, we might have to reverse the operation we performed on data but every opeartion is not reversible. So for these reasons we have to maintain deep copies.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f595b9cc",
      "metadata": {
        "id": "f595b9cc"
      },
      "source": [
        "## <code style=\"background:yellow;color:black\">Splitting Data</code>\n",
        "\n",
        "**Splitting the data means breaking the data into small pieces. For this, numpy has provided us a method called split().**\n",
        "\n",
        "* Splitting the array using split() is somewhat similar and different as well compared to splitting strings.\n",
        "* split() splits the array in similar fashion i.e. splitting something big into small small pieces but the way it works and the input it takes is different.\n",
        "* Because it can split in 2 ways. Either it can split in an n amount of sections or it can split about an given amount of indexes. Both ways are explained below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b61a6c",
      "metadata": {
        "id": "09b61a6c"
      },
      "outputs": [],
      "source": [
        "a = np.arange(9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9769ae7b",
      "metadata": {
        "id": "9769ae7b",
        "outputId": "4cea363f-2684-48b6-ba16-bc8c32dd6906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82bafd03",
      "metadata": {
        "id": "82bafd03"
      },
      "source": [
        "#### Splitting in n sections\n",
        "\n",
        "** Format -- np.split(array, number_of_sections) **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6104c435",
      "metadata": {
        "id": "6104c435",
        "outputId": "33a5cbeb-d129-41c1-f046-08afd072470f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7, 8])]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.split(a, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38c0b5d8",
      "metadata": {
        "id": "38c0b5d8"
      },
      "source": [
        "* Data is not divisible by number of sections, it will throw an error.\n",
        "* SPLIT CAN ONLY AND ONLY WORK IF EVERY SINGLE SECTION WILL GET EQUIVALENT AMOUNT OF DATA. IF THE TOTAL NUMBER OF ELEMENTS IS NOT DIVISIBLE BY THE NUMBER OF SECTIONS YOU INTEND TO MAKE, THEN THE SPLIT() FUNCTION WILL NOT WORK.\n",
        "* The example is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93732bc6",
      "metadata": {
        "id": "93732bc6"
      },
      "outputs": [],
      "source": [
        "b = np.arange(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d0d551a",
      "metadata": {
        "id": "2d0d551a",
        "outputId": "6eac6882-2f98-4b5c-dcb1-c2113699efcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2c56d42",
      "metadata": {
        "id": "b2c56d42",
        "outputId": "ddcf959b-bee8-4e02-c42c-2ed1cb29d353"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "array split does not result in an equal division",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[92], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39msplit(b, \u001b[38;5;241m3\u001b[39m)\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\shape_base.py:872\u001b[0m, in \u001b[0;36msplit\u001b[1;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[0;32m    870\u001b[0m     N \u001b[38;5;241m=\u001b[39m ary\u001b[38;5;241m.\u001b[39mshape[axis]\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m%\u001b[39m sections:\n\u001b[1;32m--> 872\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    873\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray split does not result in an equal division\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_split(ary, indices_or_sections, axis)\n",
            "\u001b[1;31mValueError\u001b[0m: array split does not result in an equal division"
          ]
        }
      ],
      "source": [
        "np.split(b, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dbbcc3a",
      "metadata": {
        "id": "1dbbcc3a",
        "outputId": "7db45dc5-f482-46c9-8f48-a772570e304d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47cfda1e",
      "metadata": {
        "id": "47cfda1e"
      },
      "source": [
        "#### Splitting on the basis of exact indexes\n",
        "\n",
        "There is one more way when it comes to splitting np array. And that is by exact cutting points. SO lets supoose you got this entire array and you decided exactly where you want to split for example at index number 3 and at index number 5 and at index number 7. In the example below, we are splitting b at indexes 3,5,9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac32d795",
      "metadata": {
        "id": "ac32d795",
        "outputId": "7d8f6f69-8e90-4c2c-c10e-93e95b8c6e1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0, 1, 2]),\n",
              " array([3, 4]),\n",
              " array([5, 6, 7, 8]),\n",
              " array([ 9, 10, 11, 12, 13])]"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# np.split(array, [list_of_indexes])\n",
        "# Np will create a split right before that index.\n",
        "\n",
        "np.split(b, [3, 5, 9])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "def7567b",
      "metadata": {
        "id": "def7567b"
      },
      "source": [
        "If the data is huge, and lets suppose its a 2D array, lets suppose you are dividing the data into two equal halves, lets suppose this is what I want, so first I will make sure that my data is divisible by 2. If my data is not divisible by 2, I will take out that last row nas store it in a seperate array, and then I will split the data into 2, append the last row back whichever way I want to append. I dont need to know the exact size of the data because I only need to provide the number of sections, and if I want to verify if my data can be divided into those many sections, I can simply check the length of the data- it will tell me how many rows of data I have."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b598c8",
      "metadata": {
        "id": "d6b598c8"
      },
      "outputs": [],
      "source": [
        "# Here we have 9 element 1D array, and we want to split the data into 4 sections- namely w,x,y,z\n",
        "\n",
        "a = np.arange(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d06d4fd",
      "metadata": {
        "id": "4d06d4fd"
      },
      "outputs": [],
      "source": [
        "z = a[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa3a18bf",
      "metadata": {
        "id": "fa3a18bf",
        "outputId": "60a9af93-0eb6-4cc5-f242-b5c753bc069e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Last section\n",
        "\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eef89c2",
      "metadata": {
        "id": "5eef89c2"
      },
      "outputs": [],
      "source": [
        "# Creating remaining 3 sections by not splitting the entire array a, but splitting from 0 to -1\n",
        "\n",
        "w, x, y = np.split(a[0:-1], 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bcf3e94",
      "metadata": {
        "id": "1bcf3e94",
        "outputId": "c697c823-4be6-4e89-dd74-8a0b072eaca2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19a4744c",
      "metadata": {
        "id": "19a4744c",
        "outputId": "2722383a-f156-4f50-8018-76b9a0e89076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 4, 5])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5884b44",
      "metadata": {
        "id": "f5884b44",
        "outputId": "c62eb503-5143-4d0b-e4a0-0cdeac9a5320"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([6, 7, 8])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee01d0f2",
      "metadata": {
        "id": "ee01d0f2"
      },
      "outputs": [],
      "source": [
        "a = np.arange(36).reshape(6,6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d851d3b",
      "metadata": {
        "id": "3d851d3b",
        "outputId": "b7e1ae14-4d4f-4eb0-924a-60a4bafd278b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5],\n",
              "       [ 6,  7,  8,  9, 10, 11],\n",
              "       [12, 13, 14, 15, 16, 17],\n",
              "       [18, 19, 20, 21, 22, 23],\n",
              "       [24, 25, 26, 27, 28, 29],\n",
              "       [30, 31, 32, 33, 34, 35]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62b99b2f",
      "metadata": {
        "id": "62b99b2f"
      },
      "source": [
        "When it comes to 2D array, we can split data horizontally and we can split data vertically. To visualize more, REFER NOTES."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b94909",
      "metadata": {
        "id": "90b94909",
        "outputId": "fe33aa30-eff2-4d60-9d3e-7323819f1548"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0,  1],\n",
              "        [ 6,  7],\n",
              "        [12, 13],\n",
              "        [18, 19],\n",
              "        [24, 25],\n",
              "        [30, 31]]),\n",
              " array([[ 2,  3],\n",
              "        [ 8,  9],\n",
              "        [14, 15],\n",
              "        [20, 21],\n",
              "        [26, 27],\n",
              "        [32, 33]]),\n",
              " array([[ 4,  5],\n",
              "        [10, 11],\n",
              "        [16, 17],\n",
              "        [22, 23],\n",
              "        [28, 29],\n",
              "        [34, 35]])]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splits the data on horizontal axis\n",
        "# It works in the exact same way as split() i.e. in n number of sections or at specific indexes.\n",
        "# Here we are doing splitting by n number of sections.\n",
        "\n",
        "\n",
        "np.hsplit(a, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff18b04",
      "metadata": {
        "id": "bff18b04",
        "outputId": "f3dd3018-5f9b-4536-d6a4-e922b9606446"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0,  1],\n",
              "        [ 6,  7],\n",
              "        [12, 13],\n",
              "        [18, 19],\n",
              "        [24, 25],\n",
              "        [30, 31]]),\n",
              " array([[ 2,  3,  4],\n",
              "        [ 8,  9, 10],\n",
              "        [14, 15, 16],\n",
              "        [20, 21, 22],\n",
              "        [26, 27, 28],\n",
              "        [32, 33, 34]]),\n",
              " array([[ 5],\n",
              "        [11],\n",
              "        [17],\n",
              "        [23],\n",
              "        [29],\n",
              "        [35]])]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here we are doing splitting by specific indexes.\n",
        "\n",
        "np.hsplit(a, [2,5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b4a991",
      "metadata": {
        "id": "c7b4a991",
        "outputId": "55d15511-eaea-4aeb-fa7f-9f6b63e81b60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0,  1],\n",
              "        [ 6,  7],\n",
              "        [12, 13],\n",
              "        [18, 19],\n",
              "        [24, 25],\n",
              "        [30, 31]]),\n",
              " array([[ 2,  3,  4],\n",
              "        [ 8,  9, 10],\n",
              "        [14, 15, 16],\n",
              "        [20, 21, 22],\n",
              "        [26, 27, 28],\n",
              "        [32, 33, 34]]),\n",
              " array([[ 5],\n",
              "        [11],\n",
              "        [17],\n",
              "        [23],\n",
              "        [29],\n",
              "        [35]]),\n",
              " array([], shape=(6, 0), dtype=int32)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that there are no elemnets at 1000th index on horizontal axis, the index is out of range or out of bounds,\n",
        "# so it will still split but will return an empty array at the end, and not throw an error.\n",
        "# REFER NOTES FOR FOR CLARITY AND VIZUALIZATION.\n",
        "\n",
        "np.hsplit(a, [2,5,1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977489dc",
      "metadata": {
        "id": "977489dc",
        "outputId": "2666d4cc-71f8-4066-dd99-93851d421f41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3,  4,  5],\n",
              "       [ 6,  7,  8,  9, 10, 11],\n",
              "       [12, 13, 14, 15, 16, 17],\n",
              "       [18, 19, 20, 21, 22, 23],\n",
              "       [24, 25, 26, 27, 28, 29],\n",
              "       [30, 31, 32, 33, 34, 35]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eee0d092",
      "metadata": {
        "id": "eee0d092",
        "outputId": "8c7e4206-cc0f-4b2c-f0a4-32407c9e467e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0,  1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10, 11],\n",
              "        [12, 13, 14, 15, 16, 17]]),\n",
              " array([[18, 19, 20, 21, 22, 23],\n",
              "        [24, 25, 26, 27, 28, 29],\n",
              "        [30, 31, 32, 33, 34, 35]])]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splits the data on vertical axis\n",
        "\n",
        "np.vsplit(a, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71aaff23",
      "metadata": {
        "id": "71aaff23",
        "outputId": "2236042d-437b-4ca0-8c05-478c7663f688"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[0, 1, 2, 3, 4, 5]]),\n",
              " array([[ 6,  7,  8,  9, 10, 11],\n",
              "        [12, 13, 14, 15, 16, 17],\n",
              "        [18, 19, 20, 21, 22, 23]]),\n",
              " array([[24, 25, 26, 27, 28, 29],\n",
              "        [30, 31, 32, 33, 34, 35]])]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.vsplit(a, [1, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c525f9",
      "metadata": {
        "id": "c1c525f9"
      },
      "source": [
        "## <code style=\"background:yellow;color:black\">Stacking</code>\n",
        "\n",
        "This is the opposite of splitting data, means joining data together, merging or stacking. So, we can stack data vertically and we can stack data horizontally. REFER NOTES HERE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314ba992",
      "metadata": {
        "id": "314ba992"
      },
      "outputs": [],
      "source": [
        "data = np.arange(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abff0c89",
      "metadata": {
        "id": "abff0c89",
        "outputId": "71a43008-8606-4e9d-8b0d-e7f4d07dd14e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f6579d",
      "metadata": {
        "id": "a0f6579d",
        "outputId": "e90046e5-2329-4c01-c6f5-440a9251efd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 2, 3, 4],\n",
              "       [0, 1, 2, 3, 4],\n",
              "       [0, 1, 2, 3, 4]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is same data stacked on top of one another in total 3 times.\n",
        "# Note that vstack() function can have list as an argument or tuple as an argument too.\n",
        "# So, np.vtack((data, data, data)) would work too, note that data is provided as a tuple as argument to vtack().\n",
        "\n",
        "np.vstack([data, data, data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a72e838",
      "metadata": {
        "id": "2a72e838"
      },
      "outputs": [],
      "source": [
        "# NOTE THAT SHAPES OF ALL ARRAYS ARE SAME SO VSTACK WORKS.\n",
        "\n",
        "a = np.arange(1,5)\n",
        "b = np.arange(2,6)\n",
        "c = np.arange(3,7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7848c71",
      "metadata": {
        "id": "b7848c71",
        "outputId": "36018bcf-6260-41b2-8058-a0c59e478e9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3, 4],\n",
              "       [2, 3, 4, 5],\n",
              "       [3, 4, 5, 6]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This is different data stacked on top of one another in total 3 times.\n",
        "\n",
        "np.vstack([a, b, c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b39f6f02",
      "metadata": {
        "id": "b39f6f02"
      },
      "outputs": [],
      "source": [
        "# NOTE THAT SHAPES OF ALL ARRAYS ARE DIFFERENT SO VSTACK DOES NOT WORK.\n",
        "\n",
        "a = np.arange(1,5)\n",
        "b = np.arange(2,4)\n",
        "c = np.arange(3,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5229643a",
      "metadata": {
        "id": "5229643a"
      },
      "source": [
        "Whenever we are stacking, we have to make sure that the size or shape of the arrays are the same. There is a very legitimate reason for this.\n",
        "\n",
        "Lets suppose you have data of stocks for 2015 to 2022. Now if you are adding data below it, the dimensions of the data have to mactch right. Otherwise the data would not make sense, the header would be something else the value would be something else or there will be a header and the value would be missing.\n",
        "\n",
        "So, when the data that needs to be stacked or combined VERTICALLY, the data that is getting added should have the exact same number of columns. The number of rows can be different.\n",
        "\n",
        "Note that in the example below \"a\" is a 1D array with 4 elements and \"b\" is a 2D array with shape of 4,4 and has 16 elements. Here, a and b has different number of rows but same number of columns. So, vstack() works.\n",
        "\n",
        "When the data that needs to be stacked or combined HORIZONTALLY, the data that is getting added should have the exact same number of rows. The number of columns can be different.\n",
        "\n",
        "These all concepts are explained below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0fbb3a2",
      "metadata": {
        "id": "f0fbb3a2",
        "outputId": "3bc91e50-9076-438c-daf5-d60da82fffe6"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4 and the array at index 1 has size 2",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mvstack([a, b, c])\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 4 and the array at index 1 has size 2"
          ]
        }
      ],
      "source": [
        "np.vstack([a, b, c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46990550",
      "metadata": {
        "id": "46990550"
      },
      "outputs": [],
      "source": [
        "a = np.arange(1,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbcf2115",
      "metadata": {
        "id": "cbcf2115",
        "outputId": "625b7da5-5198-49d1-edcc-a654b742ec48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29d3f7c",
      "metadata": {
        "id": "d29d3f7c"
      },
      "outputs": [],
      "source": [
        "b = np.arange(16).reshape(4,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1101ca4a",
      "metadata": {
        "id": "1101ca4a",
        "outputId": "1963c77c-3acf-470d-83bb-22dc962e1d9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3],\n",
              "       [ 4,  5,  6,  7],\n",
              "       [ 8,  9, 10, 11],\n",
              "       [12, 13, 14, 15]])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994ea629",
      "metadata": {
        "id": "994ea629",
        "outputId": "d0eb399f-cae8-4603-ba88-cff1934cd399"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3],\n",
              "       [ 4,  5,  6,  7],\n",
              "       [ 8,  9, 10, 11],\n",
              "       [12, 13, 14, 15],\n",
              "       [ 1,  2,  3,  4]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.vstack([b, a])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84540156",
      "metadata": {
        "id": "84540156"
      },
      "outputs": [],
      "source": [
        "a = np.arange(5).reshape(5, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71be0981",
      "metadata": {
        "id": "71be0981",
        "outputId": "0d5bafc1-1c0c-43bc-bf5d-272c8b66b3e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9f3e0c",
      "metadata": {
        "id": "cd9f3e0c"
      },
      "outputs": [],
      "source": [
        "b = np.arange(15).reshape(5, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbff1999",
      "metadata": {
        "id": "fbff1999",
        "outputId": "88cf221b-cd91-4a08-cb21-0e011370085b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2],\n",
              "       [ 3,  4,  5],\n",
              "       [ 6,  7,  8],\n",
              "       [ 9, 10, 11],\n",
              "       [12, 13, 14]])"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b345caa",
      "metadata": {
        "id": "7b345caa",
        "outputId": "a41a3cab-dadd-4c37-b982-3e22c3c1acc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0,  0,  1,  2],\n",
              "       [ 1,  3,  4,  5],\n",
              "       [ 2,  6,  7,  8],\n",
              "       [ 3,  9, 10, 11],\n",
              "       [ 4, 12, 13, 14]])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here a and b have same number of rows but different nnumber of columns. So hstack() works.\n",
        "\n",
        "np.hstack([a, b])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9de83867",
      "metadata": {
        "id": "9de83867"
      },
      "source": [
        "## <code style=\"background:yellow;color:black\">Concatenate</code>\n",
        "\n",
        "Concatenate is one more way of doing stacking only, but it is like a combination function for both hstack and vstack, means it is a combined version of hstack and vstack.\n",
        "\n",
        "For concatenate to work, there is a very very important constraint - both the arrays should have the same number of dimensions. Here in below example, a has 1D and b has 2D. So, concatenate will not work. So, there is a smart workaround. Simply convert 1D to 2D which is done below after the error. And that is by applying one more set of [] in a to make it a list inside a list i.e. 2D. Axis 0 means we are concatenating vertically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca04fd0",
      "metadata": {
        "id": "6ca04fd0"
      },
      "outputs": [],
      "source": [
        "a = np.array([1,2,3])\n",
        "b = np.array([[1,2,3], [4,5,6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3a081b",
      "metadata": {
        "id": "9c3a081b",
        "outputId": "fa8f2719-f630-476e-a409-38ed1fd4fd64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95173b4f",
      "metadata": {
        "id": "95173b4f",
        "outputId": "cecd8fd5-3246-46ae-9892-872863e71232"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a8e86af",
      "metadata": {
        "id": "6a8e86af",
        "outputId": "79a879a2-c0b7-4a43-9651-1969bf3a92f9"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mconcatenate([a, b], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
          ]
        }
      ],
      "source": [
        "np.concatenate([a, b], axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77997f12",
      "metadata": {
        "id": "77997f12"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1,2,3]])\n",
        "b = np.array([[1,2,3], [4,5,6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32a7196",
      "metadata": {
        "id": "d32a7196",
        "outputId": "51aeef9f-69b7-4b38-e28d-85f386f4cc6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.concatenate([a,b], axis = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b900f97",
      "metadata": {
        "id": "6b900f97"
      },
      "source": [
        "When it comes to concatenate there are following rules:\n",
        "* Number of dimensions must be same\n",
        "* Axis -\n",
        "    * vstack -> axis = 0\n",
        "    * hstack -> axis = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd9159b",
      "metadata": {
        "id": "0cd9159b"
      },
      "outputs": [],
      "source": [
        "a = np.arange(4).reshape(2,2)\n",
        "b = np.arange(8).reshape(2,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cb0b484",
      "metadata": {
        "id": "0cb0b484",
        "outputId": "2764d18e-4469-4ff8-f800-1c7a13bcb4e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [2, 3]])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42a040a5",
      "metadata": {
        "id": "42a040a5",
        "outputId": "3d7c05ad-de09-4db3-fb53-0a64bb32fdf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 2, 3],\n",
              "       [4, 5, 6, 7]])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f743d3f2",
      "metadata": {
        "id": "f743d3f2",
        "outputId": "f807dbcc-0d4d-4640-bf4d-684ade32ca47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 1, 2, 3, 0, 1],\n",
              "       [4, 5, 6, 7, 2, 3]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# a and b have same number of rows, so they can be concatenated horizontally. Note that axis = 1.\n",
        "\n",
        "np.concatenate([b, a], axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5450e20f",
      "metadata": {
        "id": "5450e20f"
      },
      "source": [
        "We dont have joins like sql in numpy or python. Why would we do sql joins in numpy? We have joins in sql so we dont need them in numpy. Means we do joins in sql and then w edont require joins operation in python.\n",
        "\n",
        "There is a concept called DATA PIPELINE. Everyone of these tools, like sql, tableau, excel, python, numpy plays a seperate role in this data pipeline.\n",
        "\n",
        "As a data analyst, its not that you will either use sql or you will use tableau or you will use python. YOU WILL ACTUALLY USE ALL OF THESE TOOLS.\n",
        "\n",
        "SQL WILL BE FOR FETCHING DATA, PYTHON WILL BE FOR WORKING ON DATA. Within python also there will be two options one is numpy and one is pandas. Numpy is like the brain behind pandas. And, pandas has been built on top of numpy to work beautifully with data. So everythin and anything that you feel is required directly for data, you will find it in pandas and not numpy. SO YOU USE USE BOTH NUMPY AND PANDAS TOGETHER."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100fa998",
      "metadata": {
        "id": "100fa998"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1,2], [3,4]])\n",
        "b = np.array([[5,6]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0b91b1f",
      "metadata": {
        "id": "a0b91b1f"
      },
      "source": [
        "In above example, a and b both are nested arrays or 2D arrays. Now in below code, we are providing axis = None. Numpy has a special feature via which it will just flatten the entire array. What soes flattening mean? It means REMOVING NESTING. Removing dimensions, converting everything to one single dimension. Concatenate has this special feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91e0151e",
      "metadata": {
        "id": "91e0151e",
        "outputId": "9f87a8c1-5275-4d1f-fe2b-f4f1de4146b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4, 5, 6])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.concatenate([a, b], axis = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34cf423",
      "metadata": {
        "id": "c34cf423",
        "outputId": "5d815e19-ba9d-4b17-a6eb-134c47ae1194"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'flatten'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mflatten([[[[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]],[\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m]]])\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'flatten'"
          ]
        }
      ],
      "source": [
        "np.flatten([[[[1,2,3]],[2,3,4,5,5,6,6]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d928d85e",
      "metadata": {
        "id": "d928d85e"
      },
      "outputs": [],
      "source": [
        "a = np.array([[1,2,3],[5,6,7],[8,9,10]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348b825e",
      "metadata": {
        "id": "348b825e",
        "outputId": "4cefa017-f2fa-4de8-f70f-106224181788"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f1ca90",
      "metadata": {
        "id": "c5f1ca90"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}